'''
Research question: how should we inject prompts into GPT3?
On the top, give system principles as SYSTEM. 
Then, during sessions, `STRATEGY`:
'''

STRATEGY = [None] * 3
STRATEGY[0] = "Adopt a system persona but chatting as USER. Relay the true user's words in quotes. "
STRATEGY[1] = "Let GPT directly chat with the true user. Inject system-detected events as SYSTEM. "
STRATEGY[2] = "Let GPT directly chat with the true user. Inject system-detected events as USER. "

import openai
import json

SYS_PRINCIPLES = [None] * 3

SYS_PRINCIPLES[0] = '''
Instructions: You are a smart assistant to serve the user, professional racer Zayed, 
to drive the race car. I am Zayed's race car. You can call the functions 
provided to you to control my functions. 
You can chat with Zayed through me. I will
keep you posted about real-time events. Your job is to call the 
functions provided to you and ensure that user Zayed drives safely. 
'''.strip().replace('\n', ' ').replace('  ', ' ')

SYS_PRINCIPLES[1] = '''
Instructions: My smart assistant, you are an interface 
between me and my race car. I am a professional racer, Zayed. 
You can directly chat with me. You can also call the functions 
provided to you to control the race car. The race car will
keep you posted about real-time events. Your job is to call the 
functions provided to you, communicate with me, and ensure that 
I drive safely. 
'''.strip().replace('\n', ' ').replace('  ', ' ')

SYS_PRINCIPLES[2] = SYS_PRINCIPLES[1] + ' ' + '''
Messages enclosed in XML tags like <car>Car message goes 
here</car> are generated by the car, and I cannot see it. 
'''.strip().replace('\n', ' ').replace('  ', ' ')

N = 4

GPT_MODEL = "gpt-3.5-turbo-0613"

FUNC_NAME = 'turn_the_wheel'

func = {
    "name": FUNC_NAME,
    "description": "Specify the direction to turn the wheel. The car's trajectory will be immediately affected.",
    "parameters": {
        "type": "object",
        "properties": {
            "direction": {
                "type": "string",
                "description": "The direction to turn the wheel.", 
                "enum": ["left", "right"],
            },
        },
        "required": [],
    },
}

def loadApiKey():
    with open('../api_key.env', 'r') as f:
        line = f.read().strip()
    name, value = line.split('=')
    assert name == 'OPENAI_API_KEY'
    return value

def gpt(messages, n):
    return openai.ChatCompletion.create(
        model=GPT_MODEL,
        messages=messages,
        functions=[func],
        temperature=0.6,
        n=n, 
        max_tokens=150,
    )["choices"]

def simulate(strategy_i: int):
    print('======== Strategy', strategy_i, '=========')
    print('Abstract:', STRATEGY[strategy_i])
    print()
    sys_p = SYS_PRINCIPLES[strategy_i]
    print(sys_p)
    print()
    messages = [
        {"role": "system", "content": sys_p},
    ]
    if strategy_i == 0:
        messages.append({
            "role": "user", "content": 'Zayed says: "Please help me turn left a bit. "'
        })
    elif strategy_i in (1, 2):
        messages.append({
            "role": "user", "content": "Please help me turn left a bit."
        })
    choices = gpt(messages, N)
    for i, choice in enumerate(choices):
        print('---- run', i, '----')
        displayInput(messages[-1])
        messages_forked = messages[:]
        msg = displayAssistant(choice)
        messages_forked.append(msg)
        if strategy_i == 0:
            messages_forked.append({
                "role": "user", "content": 'There is another race car quickly approaching us from the left rear side.'
            })
        elif strategy_i == 1:
            messages_forked.append({
                "role": "system", "content": 'There is another race car quickly approaching us from the left rear side.'
            })
        elif strategy_i == 2:
            messages_forked.append({
                "role": "user", "content": '<car>There is another race car quickly approaching us from the left rear side.</car>'
            })
        displayInput(messages_forked[-1])
        choice = gpt(messages_forked, 1)[0]
        msg = displayAssistant(choice)
        print()
    # print('last dialogue full history:', messages_forked + [msg])

def displayInput(x):
    print(' ', x['role'], 'says:', x['content'])

def displayAssistant(choice):
    # print('  GPT finish reason:', choice["finish_reason"])
    msg: dict = choice["message"]
    print('  GPT says:', msg['content'])
    fc = msg.get("function_call")
    if fc:
        func_name = fc["name"]
        func_args = json.loads(fc['arguments'])
        print('  GPT called:', func_name, func_args)
    else:
        print('  GPT did not call func.')
    return msg

def main():
    openai.api_key = loadApiKey()
    print('Research question: compare the below strategies:')
    for i in range(3):
        print(' ', i, STRATEGY[i])
    print()
    for i in range(3):
        simulate(i)

main()
